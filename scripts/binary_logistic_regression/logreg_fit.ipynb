{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7207ba5c-2322-41f9-a805-efe7ac5044eb",
   "metadata": {},
   "source": [
    "# Training a classifier on all datasets and establishing a regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddfedb3d-1205-4b3c-bbf5-3bf548a81ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "sys.path.append('../')\n",
    "\n",
    "import core.core_functions as cf\n",
    "import core.dataset_functions as df\n",
    "import core.plot_functions as pf\n",
    "\n",
    "land_masked = True\n",
    "global_mean = True\n",
    "# set to a not-None value to draw the same random samples for repeated calls\n",
    "random_init = 6546"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f377d-2125-4558-87a7-c2ae660336fb",
   "metadata": {},
   "source": [
    "## Load and prepare training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69bb5ba-c03e-4ed1-9862-4a9df0dbc69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we want the same amount of samples in the observation and the model category\n",
    "# therefore we call get_samples separately for both categories and change the number\n",
    "# of time steps selected\n",
    "samples_model = cf.get_samples(\n",
    "    period=slice('1982', '2001'), \n",
    "    land_masked=land_masked,\n",
    "    global_mean=global_mean,\n",
    "    time_steps=200, \n",
    "    random_init=random_init, \n",
    "    verbose=True, \n",
    "    datasets=df.model_names,  # 43 models\n",
    ")\n",
    "\n",
    "samples_obs = cf.get_samples(\n",
    "    period=slice('1982', '2001'), \n",
    "    land_masked=land_masked,\n",
    "    global_mean=global_mean,\n",
    "    time_steps=2150,  # 200*43/4\n",
    "    random_init=random_init, \n",
    "    verbose=True,\n",
    "    datasets=df.observation_names,  # 4 observations\n",
    ")\n",
    "\n",
    "samples = xr.concat([samples_model, samples_obs], dim='sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f6a790-79c5-42a6-8856-aea959c27cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = samples.values\n",
    "yy = df.get_category_ids(samples['dataset_name'].values)\n",
    "\n",
    "nan_mask = np.any(np.isnan(XX), axis=0)\n",
    "XX = XX[:, ~nan_mask]\n",
    "\n",
    "print('Number of features:', XX.shape[1])\n",
    "print('Number of samples per category:', ', '.join(np.unique(yy, return_counts=True)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cbb8d-c9d5-49da-91e9-1cbe45cafb1c",
   "metadata": {},
   "source": [
    "## Set up cross validation to establish regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10bfae-3107-4c9c-b4a1-d0b9bfde275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "grid = {'C': np.logspace(-5, -1, 20)}\n",
    "\n",
    "# 5-fold cross validation on shuffled training data\n",
    "XX, yy = shuffle(XX, yy, random_state=random_init)\n",
    "cv = 5\n",
    "\n",
    "# alternatively we could do folds for each dataset of dataset group\n",
    "# this is very slow though\n",
    "# groups = samples['dataset_name'].values  # one fold for each dataset\n",
    "# groups = df.get_groups(samples['dataset_name'].values)  # one fold for each group\n",
    "# cv = GroupKFold(n_splits=len(np.unique(groups)))\n",
    "# print('Number of dataset groups (=folds):', cv.n_splits)\n",
    "# cv.split(XX, yy, groups)\n",
    "\n",
    "logreg_cv = GridSearchCV(\n",
    "    estimator=logreg, \n",
    "    param_grid=grid, \n",
    "    cv=cv, \n",
    "    n_jobs=20, \n",
    "    return_train_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441189e-fcc1-430f-8a6f-d354045b3be4",
   "metadata": {},
   "source": [
    "## Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483f796-80b0-45a7-abec-b1dfc3a5b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_cv.fit(XX, yy)\n",
    "print(f'{logreg_cv.best_params_=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43400ec-aea5-452e-9832-dea033e287c0",
   "metadata": {},
   "source": [
    "## Save trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfef713-d917-4a25-92ee-020b029b624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "savename =  'logreg{}.sav'.format(('_lm' if land_masked else '') + ('_gm' if global_mean else ''))\n",
    "pickle.dump(\n",
    "    logreg_cv.best_estimator_, \n",
    "    open(os.path.join('../../data/trained_classifiers', savename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2d6c16-bfdb-4452-a377-5d27761877ca",
   "metadata": {},
   "source": [
    "## Training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad117b-c0f8-491c-b5d6-c1caa1614a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_cv.score(XX, yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7dbfc-a09d-4645-962d-ef381524733a",
   "metadata": {},
   "source": [
    "## Plot classifier properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab5ff6-3439-44b8-ae41-7e07fdc890e1",
   "metadata": {},
   "source": [
    "### Regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d51fb3-9bb1-4fbc-9344-8646513b652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_hyper_param(logreg_cv, 'C', xscale='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9a2da-065b-4c14-af22-a8f7f7c51072",
   "metadata": {},
   "source": [
    "### Regression weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04090c-b69d-4519-a946-2aaf17d74d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_coef_map(logreg_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723df0d-05fb-43ef-881b-af4c710c3896",
   "metadata": {},
   "source": [
    "## Reliability diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e10118-4bab-4f0e-901b-8debd6554259",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_reliability_diagram(logreg_cv, XX, yy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Model Learning",
   "language": "python",
   "name": "model_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
